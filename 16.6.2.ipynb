{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"16.6.2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNB8yQ2vhbtqkihNBqjkHWl"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgmz4gFAcV_9","executionInfo":{"status":"ok","timestamp":1613673647707,"user_tz":480,"elapsed":19160,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"12c6e4d4-1f22-4ea3-a805-a99883912573"},"source":["import os\r\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\r\n","# For example:\r\n","# spark_version = 'spark-3.0.1'\r\n","spark_version = 'spark-3.0.1'\r\n","os.environ['SPARK_VERSION']=spark_version\r\n","\r\n","# Install Spark and Java\r\n","!apt-get update\r\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\r\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n","!pip install -q findspark\r\n","\r\n","# Set Environment Variables\r\n","import os\r\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\r\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n","\r\n","# Start a SparkSession\r\n","import findspark\r\n","findspark.init()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r                                                                               \rGet:2 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r0% [Waiting for headers] [1 InRelease 88.7 kB/88.7 kB 100%] [Connected to cloud\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","\r                                                                               \rHit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [4 InRelease 15.6 kB/88.7 kB 18%] [Connected to cloud.r-project.org (143.204\r0% [2 InRelease gpgv 15.9 kB] [4 InRelease 15.6 kB/88.7 kB 18%] [Connected to c\r                                                                               \rHit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","\r0% [2 InRelease gpgv 15.9 kB] [4 InRelease 69.2 kB/88.7 kB 78%] [Waiting for he\r0% [2 InRelease gpgv 15.9 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r                                                                               \r0% [2 InRelease gpgv 15.9 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:13 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,732 kB]\n","Get:14 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [887 kB]\n","Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,929 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,391 kB]\n","Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,360 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,162 kB]\n","Fetched 10.7 MB in 3s (3,720 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WgsGqAfXcYIS","executionInfo":{"status":"ok","timestamp":1613673657943,"user_tz":480,"elapsed":8852,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":[" # Start Spark session\r\n","from pyspark.sql import SparkSession\r\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"52msCOHscdnq","executionInfo":{"status":"ok","timestamp":1613673741067,"user_tz":480,"elapsed":6438,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"5ef77399-80ef-4419-a9b9-02ed84d06ff5"},"source":["sentenceData = spark.createDataFrame([\r\n","                                      (0, ['big','data','is','super','powerful']),\r\n","                                      (1, ['this','is','going','to','be','epic']),\r\n","], ['id','raw'])\r\n","sentenceData.show(truncate=False)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["+---+--------------------------------+\n","|id |raw                             |\n","+---+--------------------------------+\n","|0  |[big, data, is, super, powerful]|\n","|1  |[this, is, going, to, be, epic] |\n","+---+--------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xGFccQMOc0QX","executionInfo":{"status":"ok","timestamp":1613673751142,"user_tz":480,"elapsed":699,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":["# Import stop words library\r\n","from pyspark.ml.feature import StopWordsRemover"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ab1WHoenc2Vr","executionInfo":{"status":"ok","timestamp":1613673762377,"user_tz":480,"elapsed":462,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":["# Run the Remover\r\n","remover = StopWordsRemover(inputCol=\"raw\", outputCol=\"filtered\")"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WxKRCr62c5cK","executionInfo":{"status":"ok","timestamp":1613673786690,"user_tz":480,"elapsed":1567,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"2304d448-011d-4641-ce81-2f2e3b087a6e"},"source":["remover.transform(sentenceData).show(truncate=False)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["+---+--------------------------------+----------------------------+\n","|id |raw                             |filtered                    |\n","+---+--------------------------------+----------------------------+\n","|0  |[big, data, is, super, powerful]|[big, data, super, powerful]|\n","|1  |[this, is, going, to, be, epic] |[going, epic]               |\n","+---+--------------------------------+----------------------------+\n","\n"],"name":"stdout"}]}]}