{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"16.6.1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMcVtKuDHPHqUQhab6fIxE1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bo_N_z4uZyvL","executionInfo":{"status":"ok","timestamp":1613672996172,"user_tz":480,"elapsed":21568,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"22e86853-b00c-4242-9bc8-5adc5d89dcc9"},"source":["import os\r\n","# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\r\n","# For example:\r\n","# spark_version = 'spark-3.0.1'\r\n","spark_version = 'spark-3.0.1'\r\n","os.environ['SPARK_VERSION']=spark_version\r\n","\r\n","# Install Spark and Java\r\n","!apt-get update\r\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\r\n","!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\r\n","!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\r\n","!pip install -q findspark\r\n","\r\n","# Set Environment Variables\r\n","import os\r\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\r\n","os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\r\n","\r\n","# Start a SparkSession\r\n","import findspark\r\n","findspark.init()"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r0% [Connecting to security.ubuntu.com (91.189.91.38)] [Connected to cloud.r-pro\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","\r                                                                               \rGet:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\r                                                                               \rHit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\r0% [1 InRelease gpgv 242 kB] [Waiting for headers] [Connecting to security.ubun\r                                                                               \rGet:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","\r0% [1 InRelease gpgv 242 kB] [5 InRelease 14.2 kB/74.6 kB 19%] [Connecting to s\r                                                                               \rHit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 242 kB] [5 InRelease 43.1 kB/74.6 kB 58%] [Waiting for hea\r                                                                               \rGet:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,360 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,162 kB]\n","Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,732 kB]\n","Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [887 kB]\n","Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,391 kB]\n","Get:20 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,929 kB]\n","Fetched 10.7 MB in 3s (3,613 kB/s)\n","Reading package lists... Done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tl_USQjUZ_8Y","executionInfo":{"status":"ok","timestamp":1613673020105,"user_tz":480,"elapsed":10368,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":["# Start Spark session\r\n","from pyspark.sql import SparkSession\r\n","spark = SparkSession.builder.appName(\"Tokens\").getOrCreate()"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"XaLiIyCCaFRc","executionInfo":{"status":"ok","timestamp":1613673044497,"user_tz":480,"elapsed":639,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":["from pyspark.ml.feature import Tokenizer"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zP26YuZNaKQV","executionInfo":{"status":"ok","timestamp":1613673131377,"user_tz":480,"elapsed":6972,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"33cf47bd-2a28-4604-a5f1-8d48ea0fc1e3"},"source":["dataframe = spark.createDataFrame([\r\n","                                   (0, 'Spark is great'),\r\n","                                   (1, 'We are learning Spark'),\r\n","                                   (2, 'Spark is better than hadoop no doubt'),\r\n","], ['id','sentence'])\r\n","\r\n","dataframe.show()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["+---+--------------------+\n","| id|            sentence|\n","+---+--------------------+\n","|  0|      Spark is great|\n","|  1|We are learning S...|\n","|  2|Spark is better t...|\n","+---+--------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nAa2WYz2af9G","executionInfo":{"status":"ok","timestamp":1613673246804,"user_tz":480,"elapsed":851,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"e7c14a27-1fd0-42f7-e3f6-3265c023a54f"},"source":["# Tokenize sentences\r\n","tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\r\n","tokenizer"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Tokenizer_d828d31f195f"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6vTXcDjaohL","executionInfo":{"status":"ok","timestamp":1613674442221,"user_tz":480,"elapsed":810,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"1e82f413-0aee-477a-b5ee-f30fe5534af1"},"source":["# Transform and show dataframe\r\n","tokenized_df = tokenizer.transform(dataframe)\r\n","tokenized_df = remover.transform(tokenized_df)\r\n","tokenized_df.show(truncate=False)"],"execution_count":37,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------------------------------+\n","|id |sentence                            |words                                       |filtered                      |\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |[spark, great]                |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |[learning, spark]             |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|[spark, better, hadoop, doubt]|\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T6DqWs2dfM7t","executionInfo":{"status":"ok","timestamp":1613674417510,"user_tz":480,"elapsed":1085,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"531b2315-166f-4fc8-d3b8-1b8a6972a5fe"},"source":["remover.transform(tokenized_df).show(truncate=False)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------------------------------+\n","|id |sentence                            |words                                       |filtered                      |\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","|0  |Spark is great                      |[spark, is, great]                          |[spark, great]                |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |[learning, spark]             |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|[spark, better, hadoop, doubt]|\n","+---+------------------------------------+--------------------------------------------+------------------------------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RmPne3f6bS_E","executionInfo":{"status":"ok","timestamp":1613673859606,"user_tz":480,"elapsed":455,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":["# Create a function to return the length of a list\r\n","def word_list_length(word_list):\r\n","    return len(word_list)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5u1xITEbVKe","executionInfo":{"status":"ok","timestamp":1613673360960,"user_tz":480,"elapsed":854,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":["from pyspark.sql.functions import col, udf\r\n","from pyspark.sql.types import IntegerType"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"MDN_e87IbbIh","executionInfo":{"status":"ok","timestamp":1613673407369,"user_tz":480,"elapsed":446,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":["# Create a user defined function\r\n","count_tokens = udf(word_list_length, IntegerType())"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KodrLJ6RbixM","executionInfo":{"status":"ok","timestamp":1613674093662,"user_tz":480,"elapsed":1189,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"9cb998ef-2f08-4fce-9c37-e39a5fc0e34c"},"source":["# Select needed columns and don't truncate results\r\n","tokenized_df.withColumn(\"tokens\", count_tokens(col(\"words\"))).show(truncate=False)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["+---+------------------------------------+--------------------------------------------+------+\n","|id |sentence                            |words                                       |tokens|\n","+---+------------------------------------+--------------------------------------------+------+\n","|0  |Spark is great                      |[spark, is, great]                          |3     |\n","|1  |We are learning Spark               |[we, are, learning, spark]                  |4     |\n","|2  |Spark is better than hadoop no doubt|[spark, is, better, than, hadoop, no, doubt]|7     |\n","+---+------------------------------------+--------------------------------------------+------+\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hHw7XaVCdNW7","executionInfo":{"status":"ok","timestamp":1613674320877,"user_tz":480,"elapsed":485,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":["# Import stop words library\r\n","from pyspark.ml.feature import StopWordsRemover\r\n"," # Start Spark session\r\n","from pyspark.sql import SparkSession\r\n","spark = SparkSession.builder.appName(\"StopWords\").getOrCreate()\r\n","# Run the Remover\r\n","remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"rR6AOA0JdTFI","executionInfo":{"status":"ok","timestamp":1613673894987,"user_tz":480,"elapsed":463,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}}},"source":[""],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IpOqvQAjdZo7","executionInfo":{"status":"ok","timestamp":1613674100587,"user_tz":480,"elapsed":651,"user":{"displayName":"Calvin Chu","photoUrl":"","userId":"00200434978780177800"}},"outputId":"419386d3-f180-46a3-93f1-2ed7be9da2e1"},"source":["tokenized_df.show()"],"execution_count":26,"outputs":[{"output_type":"stream","text":["+---+--------------------+--------------------+\n","| id|            sentence|               words|\n","+---+--------------------+--------------------+\n","|  0|      Spark is great|  [spark, is, great]|\n","|  1|We are learning S...|[we, are, learnin...|\n","|  2|Spark is better t...|[spark, is, bette...|\n","+---+--------------------+--------------------+\n","\n"],"name":"stdout"}]}]}